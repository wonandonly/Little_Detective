# ì‹¤í–‰ë°©ë²•
# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# 1-1. ì²˜ìŒì—ë§Œ : (1) python3 -m venv venv (2) pip install -r requirements.txt
# 2. source venv/bin/activate
# 3. python main.py

# main.py
import gradio as gr
import requests
import openai
import speech_recognition as sr
from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
import os
import tempfile
from gtts import gTTS
from playsound import playsound
import uuid

from dotenv import load_dotenv
load_dotenv()

# Azure OpenAI ì„¤ì •
client = openai.AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_VERSION"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

# Custom Vision ì„¤ì •
CUSTOM_VISION_ENDPOINT = os.getenv("CUSTOM_VISION_ENDPOINT")
CUSTOM_VISION_KEY = os.getenv("CUSTOM_VISION_KEY")
CUSTOM_VISION_PROJECT_ID = os.getenv("CUSTOM_VISION_PROJECT_ID")
CUSTOM_VISION_ITERATION_NAME = os.getenv("CUSTOM_VISION_ITERATION_NAME")

# tts ê¸°ëŠ¥
def text_to_speech(text: str):
    tmp_path = f"/tmp/{uuid.uuid4().hex}.mp3"
    tts = gTTS(text, lang='ko')
    tts.save(tmp_path)
    return tmp_path

# ìŒì„± ì¸ì‹ í•¨ìˆ˜
def handle_voice_input(audio_path):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)
    try:
        user_text = recognizer.recognize_google(audio, language="ko-KR")
    except sr.UnknownValueError:
        return "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."
    except sr.RequestError:
        return "ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”."

    response = client.chat.completions.create(
        model="a24-gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ì¹œì ˆí•œ ë¶„ë¦¬ìˆ˜ê±° ì•ˆë‚´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì–´ë¦°ì´ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ì•Œë ¤ì£¼ëŠ” ê±°ë‹ˆê¹Œ ì´ëª¨í‹°ì½˜ ë§ì´ ì„ì–´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
            {"role": "user", "content": user_text}
        ]
    )
    answer = response.choices[0].message.content.strip()
    return f"""
### ğŸ” íƒì •ì˜ ëŒ€ë‹µ
<div style="border:1px solid #D8D8DA; border-radius:8px; padding:12px; background-color:#ffffff;">
{answer}
</div>
"""

def classify_and_explain(image):
    image.save("temp.jpg")
    with open("temp.jpg", "rb") as f:
        img_data = f.read()

    headers = {
        "Prediction-Key": CUSTOM_VISION_KEY,
        "Content-Type": "application/octet-stream"
    }
    url = f"{CUSTOM_VISION_ENDPOINT}/customvision/v3.0/Prediction/{CUSTOM_VISION_PROJECT_ID}/classify/iterations/{CUSTOM_VISION_ITERATION_NAME}/image"
    response = requests.post(url, headers=headers, data=img_data)

    try:
        predictions = response.json()["predictions"]
        if not predictions:
            return "ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "", None
    except (KeyError, ValueError):
        return "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.", "", None

    top_result = predictions[0]["tagName"]

    tag_kor_map = {
        'vinyl': 'ë¹„ë‹ë¥˜',
        'styrofoam': 'ìŠ¤í‹°ë¡œí¼',
        'glass': 'ìœ ë¦¬ë³‘',
        'clothes': 'ì˜ë¥˜',
        'paper': 'ì¢…ì´ë¥˜',
        'can': 'ìº”ë¥˜',
        'computer': 'ì»´í“¨í„°',
        'battery': 'íê±´ì „ì§€',
        'fluorescentlamp': 'íí˜•ê´‘ë“±',
        'plastic': 'í”Œë¼ìŠ¤í‹±ë¥˜'
    }
    top_result_kor = tag_kor_map.get(top_result, top_result)

    prompt = f"'{top_result_kor}'ëŠ” ì–´ë–¤ ì¬í™œìš© í’ˆëª©ì¸ê°€ìš”? ì–´ë–»ê²Œ ë¶„ë¦¬ë°°ì¶œí•´ì•¼ í•˜ë‚˜ìš”? ì–´ë¦°ì´ë¥¼ ìœ„í•œ ê±°ë‹ˆê¹Œ ì´ëª¨í‹°ì½˜ ë§ì´ ì„ì–´ì„œ, ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì¤˜."
    completion = client.chat.completions.create(
        model="a24-gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ì¹œì ˆí•œ ë¶„ë¦¬ìˆ˜ê±° ì•ˆë‚´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    explanation = completion.choices[0].message.content.strip()

    # âœ… TTS mp3 ê²½ë¡œ ìƒì„±
    mp3_path = text_to_speech(explanation)

    # âœ… í…ìŠ¤íŠ¸ ì¶œë ¥ + mp3 ê²½ë¡œ ì „ë‹¬
    answer_text = f"""### ğŸ” íƒì •ì˜ ëŒ€ë‹µ  
<div style="border:1px solid #D8D8DA; border-radius:8px; padding:12px; background-color:#ffffff;">{top_result_kor}</div>"""

    explanation_text = f"""### â™»ï¸ì´ë ‡ê²Œ ë²„ë ¤ìš”!  
<div style="border:1px solid #D8D8DA; border-radius:8px; padding:12px; background-color:#ffffff;">{explanation}<br><br>ğŸ‘ í™˜ê²½ì„ ìƒê°í•˜ëŠ” ë©‹ì§„ ì„ íƒì´ì—ìš” ğŸŒ±</div>"""

    return answer_text, explanation_text, mp3_path

#ë§ˆí¬ë‹¤ìš´
def process_text(text):
    return f"### ê²°ê³¼ì…ë‹ˆë‹¤\n- ì…ë ¥: **{text}**\n- ì²˜ë¦¬ ì™„ë£Œ!"

app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

#css ìŠ¤íƒ€ì¼ì„ ì ìš©í•˜ê¸° ìœ„í•œ Gradio Blocks
with gr.Blocks(css="""
footer, .svelte-1ipelgc, .wrap.svelte-1ipelgc {
    display: none !important;
}

/* í—¤ë” - ë¡œê³  ìŠ¤íƒ€ì¼ */
.logo-title {
    display: flex;
    align-items: center;
    gap: 12px;
    font-size: 24px;
    font-weight: bold;
    margin-bottom: 0;
}
.header-bar {
    background-color: #d0f0c0;
    padding: 20px 30px;
    border-radius: 0 0 16px 16px;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
}
.logo-block {
    display: flex;
    align-items: center;
    gap: 18px;
}
.header-bar {
    background-color: #d0f0c0;
    padding: 16px 24px;
    border-radius: 0 0 16px 16px;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    display: flex;
    align-items: center;
    justify-content: space-between;
}
.header-left {
    display: flex;
    align-items: center;
    gap: 16px;
}
.header-logo {
    width: 72px;
    height: auto;
    border-radius: 12px;
}
.brand-text {
    display: flex;
    flex-direction: column;
}
.brand-title {
    font-size: 24px;
    font-weight: bold;
    color: #2e7d32;
}
.brand-sub {
    font-size: 15px;
    color: #4d774e;
    margin-top: 2px;
}
.contact-info {
    font-size: 14px;
    color: #333;
    text-align: right;
    line-height: 1.5;
}
.sub-description {
    font-size: 16px;
    color: #4d774e;
    font-weight: 500;
    text-align: center;
}
.fade-in {
    opacity: 0;
    transform: scale(0.95);
    animation: fadeIn 0.6s ease-out forwards;
}
@keyframes fadeIn {
    to {
        opacity: 1;
        transform: scale(1);
    }
}
               
/* ìºë¦­í„° ì„ íƒ ë¶€ë¶„ */
.character-choice-section {
    display: flex;
    justify-content: center;
    align-items: flex-end;
    gap: 28px;
    background-color: #f3f3f3;
    padding: 24px;
    border-radius: 16px;
    margin-bottom: 24px;
    flex-wrap: wrap;
}
.choice-bubble {
    display: flex;
    align-items: center;
    gap: 12px;
}                    
.character-line {
    display: flex;
    justify-content: center;
    gap: 40px;
    background-color: #f3f3f3;
    padding: 30px;
    border-radius: 16px;
    margin-bottom: 24px;
    flex-wrap: wrap;
}
.character-img {
    width: 100px;
    height: auto;
    transition: transform 0.3s;
}
.character-img:hover {
    transform: scale(1.1);
}
.character-wrapper {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
}
.character-hover-msg {
    position: absolute;
    top: -40px;
    background: #ffffff;
    color: #333;
    border-radius: 12px;
    padding: 8px 12px;
    font-size: 14px;
    font-weight: bold;
    box-shadow: 0 2px 6px rgba(0,0,0,0.15);
    opacity: 0;
    transform: scale(0.8);
    transition: all 0.3s ease;
    white-space: nowrap;
    z-index: 5;
}
.character-wrapper {
    position: relative;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 6px;
}
.character-wrapper:hover .character-hover-msg {
    opacity: 1;
    transform: scale(1);
}
/* ë§í’ì„  */
.round-msg {
    position: relative;
    width: 130px;
    height: 130px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 14px;
    font-weight: bold;
    color: white;
    padding: 10px;
    white-space: pre-line;
    border: none;
    cursor: pointer;
}
.left-msg::after {
    content: "";
    position: absolute;
    bottom: -16px;
    left: 25%; /* ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹˜ê²Œ */
    transform: translateX(-50%);
    border-left: 10px solid transparent;
    border-right: 10px solid transparent;
    border-top: 14px solid #00aaff;
}
.right-msg::after {
    content: "";
    position: absolute;
    bottom: -16px;
    left: 75%; /* ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹˜ê²Œ */
    transform: translateX(-50%);
    border-left: 10px solid transparent;
    border-right: 10px solid transparent;
    border-top: 14px solid #ff3344;
}
.choice-wrapper {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 10px;
}
.left-msg {
    background-color: #00aaff;
    color: white;
}
.speech-bubble {
    position: relative;
    width: 300px;         
    min-height: 90px;    
    padding: 12px 16px;   
    border-radius: 30px;
    display: flex;
    align-items: center; 
    justify-content: center;
    font-size: 16px;
    font-weight: bold;
    color: white;
    white-space: normal;  
    text-align: center;
    border: none;
    cursor: pointer;
    line-height: 1.4;    
}

.bubble-text{
    color: white;
}
.bubble-text:hover {
    transform: scale(1.1);
    transition: transform 0.2s ease;
}
      
.left-bubble {
    background-color: #00aaff !important;
    color: white;
}
.left-bubble::after {
    content: "";
    position: absolute;
    /* left ê¼¬ë¦¬ ìœ„ì¹˜ ë³´ì • */
    left: -12px;
    border-right: 14px solid #00aaff;    top: 50%;
    transform: translateY(-50%);
    border-top: 10px solid transparent;
    border-bottom: 10px solid transparent;
    border-right: 14px solid #00aaff;
}
.right-bubble {
    background-color: #ff3344;
}
.right-bubble::after {
    content: "";
    position: absolute;
    top: 50%;
    right: -12px;
    transform: translateY(-50%);
    border-top: 10px solid transparent;
    border-bottom: 10px solid transparent;
    border-left: 14px solid #ff3344;
}
               
.right-msg {
    background-color: #ff3344;
    color: white;
}
.character-section {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 40px;
    padding: 20px;
    background-color: #f3f3f3;
    border-radius: 16px;
    margin-bottom: 20px;
    flex-wrap: wrap;
    text-align: center;
    flex-direction: row;
}
#ai-message, #ai-tip {
    text-align: center;
    font-size: 24px;
    font-weight: bold;
    margin-bottom: 16px;
    margin-top: 10px;
}
.bouncy-icon {
    width: 120px;
    height: auto;
    border-radius: 50%;
    animation: bounce 1s infinite;
}

@keyframes bounce {
    0%, 100% {
        transform: translateY(0px);
    }
    50% {
        transform: translateY(-6px);
    }

}
               
.tool-section {
    background-color: #ffffff;
    border: 2px solid #d0f0c0;
    border-radius: 16px;
    padding: 24px;
    margin-bottom: 24px;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
    display: flex;
    flex-direction: column;
    align-items: center;
    min-height: 630px;
}

.tool-section h3 {
    font-size: 20px;
    font-weight: bold;
    color: #2e7d32;
    margin-bottom: 16px;
}

.tool-section .gr-microphone,
.tool-section .gr-image {
    width: 100%;
    max-width: 400px;
}

.tool-section .gr-textbox {
    margin-top: 16px;
    width: 100%;
    max-width: 400px;
}
               
 #answer-box {
        border: 1px solid #D8D8DA;
        border-radius: 8px;
        padding: 12px;
        font-size: 16px;
        white-space: pre-wrap;
        min-height: 100px;
}

""") as demo:

    selected = gr.State(value=False)

    with gr.Column():

        gr.HTML("""
            <div class="header-bar">
            <div class="header-left">
                <img src="/static/logo.png" alt="ê¼¬ë§ˆí™˜ê²½íƒì • ë¡œê³ " class="header-logo" />
                <div class="brand-text">
                <div class="brand-title">ê¼¬ë§ˆí™˜ê²½íƒì •</div>
                <div class="brand-sub">ì§€êµ¬ë¥¼ ì§€í‚¤ëŠ” ì‘ì§€ë§Œ í° ì‹¤ì²œ, ì§€ê¸ˆ ì‹œì‘í•´ìš”! ğŸŒ±</div>
                </div>
            </div>
            <div class="contact-info">
                <div><strong>ë¬¸ì˜:</strong> Kideco@kidsmission.org</div>
                <div><strong>ìš´ì˜:</strong> ê¼¬ë§ˆí™˜ê²½íƒì •íŒ€</div>
            </div>
            </div>
        """)

        gr.HTML("""
        <!-- íƒì • ì¸ì‚¿ë§ -->
        <div style="display: flex; align-items: center; justify-content: center; gap: 16px; margin-bottom: 24px;">
            <img src="/static/icon.png" alt="ìºë¦­í„°" class="bouncy-icon">
            <div>
                <div style="text-align: left; font-size: 22px; font-weight: bold; margin-bottom: 6px;">
                    ì•ˆë…•! ë‚˜ëŠ” <span style="color: #2e7d32;">ê¼¬ë§ˆí™˜ê²½íƒì •</span>ì´ì•¼!
                </div>
                <div style="text-align: left; font-size: 18px;">
                    ì˜¤ëŠ˜ë„ <strong>ë¶„ë¦¬ìˆ˜ê±° ë¯¸ì…˜</strong>ì„ í•¨ê»˜í• ê²Œ!
                </div>
            </div>
        </div>

        <div class="character-choice-section">
            <div style="width: 100%; text-align: center; font-size: 23px; font-weight: bold; margin-bottom: 5px;">
            ë‘˜ ì¤‘ ì–´ë–¤ ì¹œêµ¬ë¥¼ ì„ íƒí• ë˜ìš”? í´ë¦­í•´ë³´ì„¸ìš”!
            </div>
        <div class="choice-bubble">
            <div class="character-wrapper">
                <div class="character-hover-msg">ë¶„ë¦¬ìˆ˜ê±°ë¥¼ ì˜¬ë°”ë¥´ê²Œ í•˜ë©´ ì§€êµ¬ê°€ ì›ƒì–´ìš”! ğŸ˜Š</div>
                <img src="/static/good.png" class="character-img" />
            </div>
            <button class="speech-bubble left-bubble" onclick="document.querySelector('#good-button').click()">
                <span class="bubble-text">ë¶„ë¦¬ìˆ˜ê±° ì˜í•˜ë©´<br>ì§€êµ¬ê°€ ê¹¨ë—í•´ì ¸ìš”~!</span>
            </button>
        </div>

        <div class="choice-bubble">
            <button class="speech-bubble right-bubble" onclick="document.querySelector('#bad-button').click()">
                <span class="bubble-text">ê·¸ëƒ¥ ë‹¤ í•œêº¼ë²ˆì— ë²„ë ¤~<br>ê·€ì°®ì–ì•„!</span>
            </button>
            <div class="character-wrapper">
                <div class="character-hover-msg">ì •ë§ ë‚˜ë¥¼ ì„ íƒí•  ê±°ì•¼...? ì§€êµ¬ê°€ ì•„íŒŒìš” ğŸ¥²</div>
                <img src="/static/bad.png" class="character-img" />
            </div>
        </div>
        </div>
        """)

        ai_message = gr.HTML(visible=False, elem_id="ai-message")
        ai_tip = gr.HTML(visible=False, elem_id="ai-tip")

        with gr.Row(visible=False) as tools_row:
            with gr.Column():
                with gr.Column(elem_classes="tool-section"):
                    gr.HTML("<h3>ğŸ¤ ë§ë¡œ ë¬¼ì–´ë³´ì„¸ìš”!</h3>")
                    voice_input = gr.Microphone(label="", type="filepath")
                    voice_output = gr.Markdown(label="", elem_id="answer-box")
            with gr.Column():
                with gr.Column(elem_classes="tool-section"):
                    gr.HTML("<h3>ğŸ“· ì‚¬ì§„ì„ ì˜¬ë ¤ë³´ì„¸ìš”!</h3><p>ì‚¬ì§„ì„ ì°ì„ ë•ŒëŠ” í•˜ë‚˜ì˜ ë¬¼ê±´ë§Œ ì°ì–´ì£¼ì„¸ìš”! \n ğŸ“¸ ì—¬ëŸ¬ ê°œê°€ ìˆìœ¼ë©´ AIê°€ í—·ê°ˆë¦´ ìˆ˜ ìˆì–´ìš”.</p>")
                    # ì´ë¯¸ì§€ ì…ë ¥
                    image_input = gr.Image(label="", type="pil")

                    #í…ìŠ¤íŠ¸ ì¶œë ¥
                    result = gr.Markdown(label="ê²°ê³¼", elem_id="answer-box")
                    howto = gr.Markdown(label="ì´ë ‡ê²Œ ë²„ë ¤ìš”!", elem_id="answer-box")

                     # âœ… ìŒì„± ì¬ìƒìš© ì¶”ê°€
                    play_button = gr.Button("â–¶ï¸ ìŒì„± ì¬ìƒ")
                    audio_output = gr.Audio()

                    # âœ… ë‚´ë¶€ì ìœ¼ë¡œ ìŒì„± ê²½ë¡œ ì €ì¥í•  ìƒíƒœ
                    tts_path_state = gr.State()

        def good_selected():
            return (
                gr.update(value="<div style='font-size: 26px;'>ğŸ’¡ ì¢‹ì€ ìƒê°ì´ì•¼! íƒì •ì—ê²Œ ë¬¼ì–´ë³´ì!</div>", visible=True),
                gr.update(visible=True)
            )

        def bad_selected():
            return (
                gr.update(value="<div style='font-size: 26px;'>ğŸ“š ê·¸ëŸ¬ë©´ ì•ˆ ë¼! ë¶„ë¦¬ìˆ˜ê±°ë¥¼ ê°™ì´ ë°°ì›Œë³´ì!", visible=True),
                gr.update(visible=True)
            )

        good_button = gr.Button(visible=False, elem_id="good-button")
        bad_button = gr.Button(visible=False, elem_id="bad-button")

        good_button.click(fn=good_selected, outputs=[ai_message, tools_row])
        bad_button.click(fn=bad_selected, outputs=[ai_message, tools_row])

        voice_input.change(fn=handle_voice_input, inputs=voice_input, outputs=voice_output)

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ ìë™ ì‹¤í–‰
        image_input.change(
            fn=classify_and_explain,
            inputs=image_input,
            outputs=[result, howto, tts_path_state]
        )

        # ìŒì„± ì¬ìƒ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
        play_button.click(
            fn=lambda path: path,
            inputs=tts_path_state,
            outputs=audio_output
        )

# Gradio ì•± ì‹¤í–‰
app = gr.mount_gradio_app(app, demo, path="/")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=7870)

